[2020-09-29 17:51:49,322 INFO]  * src vocab size = 1004
[2020-09-29 17:51:49,322 INFO]  * tgt vocab size = 1004
[2020-09-29 17:51:49,322 INFO] Building model...
[2020-09-29 17:51:49,390 INFO] NMTModel(
  (encoder): RNNEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(1004, 256, padding_idx=1)
        )
      )
    )
    (rnn): LSTM(256, 128, num_layers=2, dropout=0.3, bidirectional=True)
    (bridge): ModuleList(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): Linear(in_features=256, out_features=256, bias=True)
    )
  )
  (decoder): InputFeedRNNDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(1004, 256, padding_idx=1)
        )
      )
    )
    (dropout): Dropout(p=0.3, inplace=False)
    (rnn): StackedLSTM(
      (dropout): Dropout(p=0.3, inplace=False)
      (layers): ModuleList(
        (0): LSTMCell(512, 256)
        (1): LSTMCell(256, 256)
      )
    )
    (attn): GlobalAttention(
      (linear_in): Linear(in_features=256, out_features=256, bias=False)
      (linear_out): Linear(in_features=512, out_features=256, bias=False)
    )
  )
  (generator): CopyGenerator(
    (linear): Linear(in_features=256, out_features=1004, bias=True)
    (linear_copy): Linear(in_features=256, out_features=1, bias=True)
  )
)
[2020-09-29 17:51:49,390 INFO] encoder: 1179136
[2020-09-29 17:51:49,390 INFO] decoder: 2026733
[2020-09-29 17:51:49,391 INFO] * number of parameters: 3205869
[2020-09-29 17:51:49,391 INFO] Starting training on CPU, could be very slow
[2020-09-29 17:51:49,392 INFO] Start training loop and validate every 10000 steps...
[2020-09-29 17:51:49,392 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 17:51:49,547 INFO] number of examples: 2255
/usr/local/lib/python3.7/dist-packages/torchtext-0.4.0-py3.7.egg/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  var = torch.tensor(arr, dtype=self.dtype, device=device)
[2020-09-29 17:52:39,670 INFO] Step 50/ 2000; acc:   9.65; ppl: 176.29; xent: 5.17; lr: 1.00000; 1350/363 tok/s;     50 sec
[2020-09-29 17:53:16,706 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 17:53:16,913 INFO] number of examples: 2255
[2020-09-29 17:53:51,807 INFO] Step 100/ 2000; acc:  11.42; ppl: 80.64; xent: 4.39; lr: 1.00000; 1101/262 tok/s;    122 sec
[2020-09-29 17:54:45,056 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 17:54:45,210 INFO] number of examples: 2255
[2020-09-29 17:54:57,744 INFO] Step 150/ 2000; acc:  15.25; ppl: 40.59; xent: 3.70; lr: 1.00000; 1143/291 tok/s;    188 sec
[2020-09-29 17:55:55,117 INFO] Step 200/ 2000; acc:  27.27; ppl: 19.30; xent: 2.96; lr: 1.00000; 1154/318 tok/s;    246 sec
[2020-09-29 17:56:15,193 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 17:56:15,384 INFO] number of examples: 2255
[2020-09-29 17:56:57,414 INFO] Step 250/ 2000; acc:  36.53; ppl: 12.20; xent: 2.50; lr: 1.00000; 1198/298 tok/s;    308 sec
[2020-09-29 17:57:46,396 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 17:57:46,611 INFO] number of examples: 2255
[2020-09-29 17:58:07,997 INFO] Step 300/ 2000; acc:  44.25; ppl:  9.14; xent: 2.21; lr: 1.00000; 1094/272 tok/s;    379 sec
[2020-09-29 17:59:07,842 INFO] Step 350/ 2000; acc:  53.49; ppl:  6.38; xent: 1.85; lr: 1.00000; 1143/306 tok/s;    438 sec
[2020-09-29 17:59:17,174 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 17:59:17,392 INFO] number of examples: 2255
[2020-09-29 18:00:06,231 INFO] Step 400/ 2000; acc:  58.26; ppl:  5.45; xent: 1.70; lr: 1.00000; 1211/313 tok/s;    497 sec
[2020-09-29 18:00:48,144 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:00:48,360 INFO] number of examples: 2255
[2020-09-29 18:01:20,414 INFO] Step 450/ 2000; acc:  64.97; ppl:  4.39; xent: 1.48; lr: 1.00000; 1083/259 tok/s;    571 sec
[2020-09-29 18:02:19,126 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:02:19,269 INFO] number of examples: 2255
[2020-09-29 18:02:24,155 INFO] Step 500/ 2000; acc:  68.83; ppl:  3.77; xent: 1.33; lr: 1.00000; 1121/295 tok/s;    635 sec
[2020-09-29 18:03:23,618 INFO] Step 550/ 2000; acc:  72.45; ppl:  3.23; xent: 1.17; lr: 1.00000; 1155/303 tok/s;    694 sec
[2020-09-29 18:03:48,441 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:03:48,658 INFO] number of examples: 2255
[2020-09-29 18:04:26,022 INFO] Step 600/ 2000; acc:  74.18; ppl:  2.93; xent: 1.08; lr: 1.00000; 1223/305 tok/s;    757 sec
[2020-09-29 18:05:16,241 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:05:16,464 INFO] number of examples: 2255
[2020-09-29 18:05:32,899 INFO] Step 650/ 2000; acc:  76.89; ppl:  2.68; xent: 0.98; lr: 1.00000; 1152/287 tok/s;    824 sec
[2020-09-29 18:06:30,536 INFO] Step 700/ 2000; acc:  77.96; ppl:  2.54; xent: 0.93; lr: 1.00000; 1171/317 tok/s;    881 sec
[2020-09-29 18:06:44,194 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:06:44,414 INFO] number of examples: 2255
[2020-09-29 18:07:28,587 INFO] Step 750/ 2000; acc:  80.22; ppl:  2.29; xent: 0.83; lr: 1.00000; 1244/318 tok/s;    939 sec
[2020-09-29 18:08:11,953 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:08:12,176 INFO] number of examples: 2255
[2020-09-29 18:08:34,800 INFO] Step 800/ 2000; acc:  80.76; ppl:  2.26; xent: 0.82; lr: 1.00000; 1148/285 tok/s;   1005 sec
[2020-09-29 18:09:37,656 INFO] Step 850/ 2000; acc:  82.02; ppl:  2.07; xent: 0.73; lr: 1.00000; 1143/294 tok/s;   1068 sec
[2020-09-29 18:09:39,692 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:09:39,845 INFO] number of examples: 2255
[2020-09-29 18:10:29,128 INFO] Step 900/ 2000; acc:  83.72; ppl:  1.92; xent: 0.65; lr: 1.00000; 1298/354 tok/s;   1120 sec
[2020-09-29 18:11:07,373 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:11:07,585 INFO] number of examples: 2255
[2020-09-29 18:11:41,202 INFO] Step 950/ 2000; acc:  82.78; ppl:  1.96; xent: 0.67; lr: 1.00000; 1131/268 tok/s;   1192 sec
[2020-09-29 18:12:35,378 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:12:35,586 INFO] number of examples: 2255
[2020-09-29 18:12:45,294 INFO] Step 1000/ 2000; acc:  83.66; ppl:  1.91; xent: 0.64; lr: 1.00000; 1145/292 tok/s;   1256 sec
[2020-09-29 18:12:45,342 INFO] Saving checkpoint /home/epicosy/thesis/implementation/repair/CquenceR/data/model/final-model_step_1000.pt
[2020-09-29 18:13:41,663 INFO] Step 1050/ 2000; acc:  84.62; ppl:  1.83; xent: 0.60; lr: 1.00000; 1192/324 tok/s;   1312 sec
[2020-09-29 18:14:02,929 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:14:03,128 INFO] number of examples: 2255
[2020-09-29 18:14:42,349 INFO] Step 1100/ 2000; acc:  84.88; ppl:  1.78; xent: 0.58; lr: 1.00000; 1231/309 tok/s;   1373 sec
[2020-09-29 18:15:30,648 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:15:30,859 INFO] number of examples: 2255
[2020-09-29 18:15:50,421 INFO] Step 1150/ 2000; acc:  85.77; ppl:  1.73; xent: 0.55; lr: 1.00000; 1154/286 tok/s;   1441 sec
[2020-09-29 18:16:51,067 INFO] Step 1200/ 2000; acc:  86.55; ppl:  1.66; xent: 0.51; lr: 1.00000; 1118/301 tok/s;   1502 sec
[2020-09-29 18:17:01,195 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:17:01,353 INFO] number of examples: 2255
[2020-09-29 18:17:48,650 INFO] Step 1250/ 2000; acc:  87.13; ppl:  1.63; xent: 0.49; lr: 1.00000; 1227/315 tok/s;   1559 sec
[2020-09-29 18:18:31,940 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:18:32,148 INFO] number of examples: 2255
[2020-09-29 18:19:03,154 INFO] Step 1300/ 2000; acc:  86.50; ppl:  1.65; xent: 0.50; lr: 1.00000; 1077/259 tok/s;   1634 sec
[2020-09-29 18:20:02,841 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:20:03,058 INFO] number of examples: 2255
[2020-09-29 18:20:05,380 INFO] Step 1350/ 2000; acc:  87.62; ppl:  1.59; xent: 0.46; lr: 1.00000; 1118/297 tok/s;   1696 sec
[2020-09-29 18:21:05,908 INFO] Step 1400/ 2000; acc:  88.14; ppl:  1.55; xent: 0.44; lr: 1.00000; 1133/297 tok/s;   1757 sec
[2020-09-29 18:21:33,476 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:21:33,680 INFO] number of examples: 2255
[2020-09-29 18:22:10,179 INFO] Step 1450/ 2000; acc:  87.38; ppl:  1.57; xent: 0.45; lr: 1.00000; 1203/298 tok/s;   1821 sec
[2020-09-29 18:23:02,902 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:23:03,132 INFO] number of examples: 2255
[2020-09-29 18:23:17,025 INFO] Step 1500/ 2000; acc:  88.32; ppl:  1.52; xent: 0.42; lr: 1.00000; 1141/288 tok/s;   1888 sec
[2020-09-29 18:24:12,679 INFO] Step 1550/ 2000; acc:  88.44; ppl:  1.50; xent: 0.41; lr: 1.00000; 1178/326 tok/s;   1943 sec
[2020-09-29 18:24:31,332 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:24:31,550 INFO] number of examples: 2255
[2020-09-29 18:25:12,899 INFO] Step 1600/ 2000; acc:  88.65; ppl:  1.50; xent: 0.41; lr: 1.00000; 1232/306 tok/s;   2004 sec
[2020-09-29 18:25:58,810 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:25:58,976 INFO] number of examples: 2255
[2020-09-29 18:26:20,382 INFO] Step 1650/ 2000; acc:  88.96; ppl:  1.47; xent: 0.38; lr: 1.00000; 1147/286 tok/s;   2071 sec
[2020-09-29 18:27:18,785 INFO] Step 1700/ 2000; acc:  89.57; ppl:  1.44; xent: 0.36; lr: 1.00000; 1167/312 tok/s;   2129 sec
[2020-09-29 18:27:27,063 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:27:27,279 INFO] number of examples: 2255
[2020-09-29 18:28:15,581 INFO] Step 1750/ 2000; acc:  89.87; ppl:  1.42; xent: 0.35; lr: 1.00000; 1249/323 tok/s;   2186 sec
[2020-09-29 18:28:54,864 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:28:55,086 INFO] number of examples: 2255
[2020-09-29 18:29:26,975 INFO] Step 1800/ 2000; acc:  89.52; ppl:  1.44; xent: 0.36; lr: 1.00000; 1118/267 tok/s;   2258 sec
[2020-09-29 18:30:23,256 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:30:23,453 INFO] number of examples: 2255
[2020-09-29 18:30:29,383 INFO] Step 1850/ 2000; acc:  90.62; ppl:  1.39; xent: 0.33; lr: 1.00000; 1158/304 tok/s;   2320 sec
[2020-09-29 18:31:28,480 INFO] Step 1900/ 2000; acc:  89.55; ppl:  1.44; xent: 0.36; lr: 1.00000; 1171/308 tok/s;   2379 sec
[2020-09-29 18:31:51,547 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:31:51,772 INFO] number of examples: 2255
[2020-09-29 18:32:29,806 INFO] Step 1950/ 2000; acc:  90.32; ppl:  1.40; xent: 0.34; lr: 1.00000; 1220/306 tok/s;   2440 sec
[2020-09-29 18:33:19,664 INFO] Loading dataset from /home/epicosy/thesis/implementation/repair/CquenceR/data/input/final.train.0.pt
[2020-09-29 18:33:19,830 INFO] number of examples: 2255
[2020-09-29 18:33:37,959 INFO] Step 2000/ 2000; acc:  90.84; ppl:  1.37; xent: 0.31; lr: 1.00000; 1150/286 tok/s;   2509 sec
[2020-09-29 18:33:38,013 INFO] Saving checkpoint /home/epicosy/thesis/implementation/repair/CquenceR/data/model/final-model_step_2000.pt
